{
    "bf16": {
        "value": false
    },
    "fp16": {
        "value": true
    },
    "fsdp": {
        "value": []
    },
    "seed": {
        "value": 42
    },
    "tf32": {
        "value": null
    },
    "debug": {
        "value": []
    },
    "dtype": {
        "value": "float16"
    },
    "optim": {
        "value": "adamw_torch_fused"
    },
    "top_k": {
        "value": 50
    },
    "top_p": {
        "value": 1
    },
    "_wandb": {
        "value": {
            "e": {
                "yxly6qqkmcgxqo6gxldsd8elgl08xwkv": {
                    "os": "Linux-6.6.105+-x86_64-with-glibc2.35",
                    "git": {
                        "commit": "28576cb7527350fbb98cecd588e808b1d41586b1",
                        "remote": "https://github.com/omid511/qwen3-1.7b-finetune-bitext"
                    },
                    "gpu": "Tesla T4",
                    "args": [
                        "--model_id",
                        "Qwen/Qwen3-1.7B",
                        "--output_dir",
                        "./qwen3-lora",
                        "--hub_model_id",
                        "omid5/Qwen3-1.7b-cusomer-support-agent",
                        "--push_to_hub",
                        "True",
                        "--use_bnb",
                        "True",
                        "--merge_and_push",
                        "--per_device_train_batch_size",
                        "8",
                        "--per_device_eval_batch_size",
                        "16",
                        "--gradient_accumulation_steps",
                        "2",
                        "--learning_rate",
                        "2e-4",
                        "--lr_scheduler_type",
                        "cosine",
                        "--warmup_ratio",
                        "0.05",
                        "--max_seq_length",
                        "400",
                        "--num_train_epochs",
                        "2",
                        "--eval_strategy",
                        "steps",
                        "--eval_steps",
                        "200",
                        "--save_steps",
                        "200",
                        "--save_total_limit",
                        "2",
                        "--logging_steps",
                        "10",
                        "--load_best_model_at_end",
                        "True",
                        "--metric_for_best_model",
                        "eval_loss",
                        "--greater_is_better",
                        "False",
                        "--disable_tqdm",
                        "False",
                        "--fp16",
                        "True",
                        "--packing",
                        "False",
                        "--dataset_text_field",
                        "text",
                        "--ddp_find_unused_parameters",
                        "True",
                        "--attn_implementation",
                        "eager"
                    ],
                    "disk": {
                        "/": {
                            "used": "7059288514560",
                            "total": "8656922775552"
                        }
                    },
                    "host": "8d8ea1a90329",
                    "root": "/kaggle/working/qwen3-1.7b-finetune-bitext",
                    "email": "omid511.orm@gmail.com",
                    "memory": {
                        "total": "33662472192"
                    },
                    "python": "CPython 3.11.13",
                    "program": "/kaggle/working/qwen3-1.7b-finetune-bitext/scripts/train_lora.py",
                    "codePath": "scripts/train_lora.py",
                    "writerId": "yxly6qqkmcgxqo6gxldsd8elgl08xwkv",
                    "cpu_count": 2,
                    "gpu_count": 2,
                    "startedAt": "2025-12-11T17:31:57.328824Z",
                    "executable": "/kaggle/working/qwen3-1.7b-finetune-bitext/.venv/bin/python",
                    "gpu_nvidia": [
                        {
                            "name": "Tesla T4",
                            "uuid": "GPU-ac754e31-3b5f-d73f-6017-8458874e81d1",
                            "cudaCores": 2560,
                            "memoryTotal": "16106127360",
                            "architecture": "Turing"
                        },
                        {
                            "name": "Tesla T4",
                            "uuid": "GPU-5cd88e98-6f2c-0a95-572c-2468b5ff5b04",
                            "cudaCores": 2560,
                            "memoryTotal": "16106127360",
                            "architecture": "Turing"
                        }
                    ],
                    "cudaVersion": "12.8",
                    "codePathLocal": "scripts/train_lora.py",
                    "cpu_count_logical": 4
                }
            },
            "m": [
                {
                    "1": "train/global_step",
                    "6": [
                        3
                    ],
                    "7": []
                },
                {
                    "2": "*",
                    "5": 1,
                    "6": [
                        1
                    ],
                    "7": []
                }
            ],
            "t": {
                "1": [
                    1,
                    11,
                    49,
                    51,
                    71,
                    84,
                    98
                ],
                "2": [
                    1,
                    11,
                    49,
                    51,
                    71,
                    84,
                    98
                ],
                "3": [
                    7,
                    19,
                    62,
                    66
                ],
                "4": "3.11.13",
                "5": "0.23.1",
                "6": "4.57.3",
                "8": [
                    2
                ],
                "9": {
                    "1": "transformers_trainer"
                },
                "12": "0.23.1",
                "13": "linux-x86_64"
            },
            "cli_version": "0.23.1",
            "python_version": "3.11.13"
        }
    },
    "prefix": {
        "value": null
    },
    "do_eval": {
        "value": true
    },
    "no_cuda": {
        "value": false
    },
    "packing": {
        "value": false
    },
    "project": {
        "value": "huggingface"
    },
    "use_cpu": {
        "value": false
    },
    "do_train": {
        "value": false
    },
    "head_dim": {
        "value": 128
    },
    "id2label": {
        "value": {
            "0": "LABEL_0",
            "1": "LABEL_1"
        }
    },
    "label2id": {
        "value": {
            "LABEL_0": 0,
            "LABEL_1": 1
        }
    },
    "run_name": {
        "value": null
    },
    "adafactor": {
        "value": false
    },
    "data_seed": {
        "value": null
    },
    "deepspeed": {
        "value": null
    },
    "do_sample": {
        "value": false
    },
    "eos_token": {
        "value": "<EOS_TOKEN>"
    },
    "hub_token": {
        "value": "<HUB_TOKEN>"
    },
    "log_level": {
        "value": "passive"
    },
    "loss_type": {
        "value": "nll"
    },
    "max_steps": {
        "value": -1
    },
    "num_beams": {
        "value": 1
    },
    "pad_token": {
        "value": "<PAD_TOKEN>"
    },
    "ray_scope": {
        "value": "last"
    },
    "report_to": {
        "value": [
            "wandb"
        ]
    },
    "typical_p": {
        "value": 1
    },
    "use_cache": {
        "value": false
    },
    "adam_beta1": {
        "value": 0.9
    },
    "adam_beta2": {
        "value": 0.999
    },
    "do_predict": {
        "value": false
    },
    "eval_delay": {
        "value": 0
    },
    "eval_steps": {
        "value": 200
    },
    "hidden_act": {
        "value": "silu"
    },
    "is_decoder": {
        "value": false
    },
    "local_rank": {
        "value": 0
    },
    "max_length": {
        "value": 1024
    },
    "min_length": {
        "value": 0
    },
    "model_type": {
        "value": "qwen3"
    },
    "optim_args": {
        "value": null
    },
    "output_dir": {
        "value": "./qwen3-lora"
    },
    "past_index": {
        "value": -1
    },
    "rope_theta": {
        "value": 1000000
    },
    "save_steps": {
        "value": 200
    },
    "vocab_size": {
        "value": 151936
    },
    "ddp_backend": {
        "value": null
    },
    "ddp_timeout": {
        "value": 1800
    },
    "fsdp_config": {
        "value": {
            "xla": false,
            "xla_fsdp_v2": false,
            "min_num_params": 0,
            "xla_fsdp_grad_ckpt": false
        }
    },
    "hidden_size": {
        "value": 2048
    },
    "label_names": {
        "value": null
    },
    "layer_types": {
        "value": [
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention",
            "full_attention"
        ]
    },
    "logging_dir": {
        "value": "./qwen3-lora/runs/Dec11_17-30-28_8d8ea1a90329"
    },
    "peft_config": {
        "value": {
            "default": {
                "r": 16,
                "bias": "none",
                "revision": null,
                "use_dora": false,
                "lora_bias": false,
                "peft_type": "LORA",
                "task_type": "CAUSAL_LM",
                "eva_config": null,
                "lora_alpha": 32,
                "use_qalora": false,
                "use_rslora": false,
                "arrow_config": null,
                "auto_mapping": null,
                "corda_config": null,
                "lora_dropout": 0.05,
                "peft_version": "0.18.0",
                "megatron_core": "megatron.core",
                "fan_in_fan_out": false,
                "inference_mode": false,
                "layers_pattern": null,
                "runtime_config": {
                    "ephemeral_gpu_offload": false
                },
                "target_modules": [
                    "down_proj",
                    "gate_proj",
                    "o_proj",
                    "v_proj",
                    "up_proj",
                    "k_proj",
                    "q_proj"
                ],
                "exclude_modules": null,
                "megatron_config": null,
                "modules_to_save": null,
                "init_lora_weights": true,
                "layer_replication": null,
                "qalora_group_size": 16,
                "target_parameters": null,
                "ensure_weight_tying": false,
                "layers_to_transform": null,
                "alora_invocation_tokens": null,
                "base_model_name_or_path": "Qwen/Qwen3-1.7B",
                "trainable_token_indices": null
            }
        }
    },
    "push_to_hub": {
        "value": true
    },
    "return_dict": {
        "value": true
    },
    "temperature": {
        "value": 1
    },
    "torchdynamo": {
        "value": null
    },
    "torchscript": {
        "value": false
    },
    "adam_epsilon": {
        "value": 1e-8
    },
    "bos_token_id": {
        "value": null
    },
    "disable_tqdm": {
        "value": false
    },
    "eos_token_id": {
        "value": 151645
    },
    "eval_packing": {
        "value": null
    },
    "fp16_backend": {
        "value": "auto"
    },
    "hub_model_id": {
        "value": "omid5/Qwen3-1.7b-cusomer-support-agent"
    },
    "hub_revision": {
        "value": null
    },
    "hub_strategy": {
        "value": "every_save"
    },
    "pad_token_id": {
        "value": 151643
    },
    "padding_free": {
        "value": false
    },
    "problem_type": {
        "value": null
    },
    "rms_norm_eps": {
        "value": 0.000001
    },
    "rope_scaling": {
        "value": null
    },
    "sep_token_id": {
        "value": null
    },
    "use_bfloat16": {
        "value": false
    },
    "warmup_ratio": {
        "value": 0.05
    },
    "warmup_steps": {
        "value": 0
    },
    "weight_decay": {
        "value": 0
    },
    "_name_or_path": {
        "value": "Qwen/Qwen3-1.7B"
    },
    "architectures": {
        "value": [
            "Qwen3ForCausalLM"
        ]
    },
    "bad_words_ids": {
        "value": null
    },
    "eval_on_start": {
        "value": false
    },
    "eval_strategy": {
        "value": "steps"
    },
    "jit_mode_eval": {
        "value": false
    },
    "learning_rate": {
        "value": 0.0002
    },
    "logging_steps": {
        "value": 10
    },
    "max_grad_norm": {
        "value": 1
    },
    "mp_parameters": {
        "value": ""
    },
    "output_scores": {
        "value": false
    },
    "save_strategy": {
        "value": "steps"
    },
    "torch_compile": {
        "value": false
    },
    "tpu_num_cores": {
        "value": null
    },
    "attention_bias": {
        "value": false
    },
    "bf16_full_eval": {
        "value": false
    },
    "dataset_kwargs": {
        "value": null
    },
    "early_stopping": {
        "value": false
    },
    "fp16_full_eval": {
        "value": false
    },
    "fp16_opt_level": {
        "value": "O1"
    },
    "length_penalty": {
        "value": 1
    },
    "sliding_window": {
        "value": null
    },
    "tf_legacy_loss": {
        "value": false
    },
    "use_mps_device": {
        "value": false
    },
    "finetuning_task": {
        "value": null
    },
    "group_by_length": {
        "value": false
    },
    "hub_always_push": {
        "value": false
    },
    "num_beam_groups": {
        "value": 1
    },
    "save_only_model": {
        "value": false
    },
    "shuffle_dataset": {
        "value": false
    },
    "suppress_tokens": {
        "value": null
    },
    "tokenizer_class": {
        "value": null
    },
    "dataset_num_proc": {
        "value": null
    },
    "full_determinism": {
        "value": false
    },
    "hub_private_repo": {
        "value": null
    },
    "ignore_data_skip": {
        "value": false
    },
    "log_on_each_node": {
        "value": true
    },
    "logging_strategy": {
        "value": "steps"
    },
    "num_train_epochs": {
        "value": 2
    },
    "packing_strategy": {
        "value": "bfd"
    },
    "save_safetensors": {
        "value": true
    },
    "save_total_limit": {
        "value": 2
    },
    "trackio_space_id": {
        "value": "trackio"
    },
    "use_liger_kernel": {
        "value": false
    },
    "attention_dropout": {
        "value": 0
    },
    "ddp_bucket_cap_mb": {
        "value": null
    },
    "diversity_penalty": {
        "value": 0
    },
    "greater_is_better": {
        "value": false
    },
    "initializer_range": {
        "value": 0.02
    },
    "intermediate_size": {
        "value": 6144
    },
    "log_level_replica": {
        "value": "warning"
    },
    "lr_scheduler_type": {
        "value": "cosine"
    },
    "max_window_layers": {
        "value": 28
    },
    "model_init_kwargs": {
        "value": null
    },
    "num_hidden_layers": {
        "value": 28
    },
    "output_attentions": {
        "value": false
    },
    "push_to_hub_token": {
        "value": "<PUSH_TO_HUB_TOKEN>"
    },
    "save_on_each_node": {
        "value": false
    },
    "tpu_metrics_debug": {
        "value": false
    },
    "accelerator_config": {
        "value": {
            "even_batches": true,
            "non_blocking": false,
            "split_batches": false,
            "dispatch_batches": null,
            "use_seedable_sampler": true,
            "gradient_accumulation_kwargs": null
        }
    },
    "batch_eval_metrics": {
        "value": false
    },
    "chat_template_path": {
        "value": null
    },
    "dataset_text_field": {
        "value": "text"
    },
    "is_encoder_decoder": {
        "value": false
    },
    "length_column_name": {
        "value": "length"
    },
    "logging_first_step": {
        "value": false
    },
    "pad_to_multiple_of": {
        "value": null
    },
    "parallelism_config": {
        "value": null
    },
    "repetition_penalty": {
        "value": 1
    },
    "torch_compile_mode": {
        "value": null
    },
    "use_sliding_window": {
        "value": false
    },
    "add_cross_attention": {
        "value": false
    },
    "assistant_only_loss": {
        "value": false
    },
    "forced_bos_token_id": {
        "value": null
    },
    "forced_eos_token_id": {
        "value": null
    },
    "fsdp_min_num_params": {
        "value": 0
    },
    "include_for_metrics": {
        "value": []
    },
    "liger_kernel_config": {
        "value": null
    },
    "lr_scheduler_kwargs": {
        "value": null
    },
    "neftune_noise_alpha": {
        "value": null
    },
    "num_attention_heads": {
        "value": 16
    },
    "num_key_value_heads": {
        "value": 8
    },
    "quantization_config": {
        "value": {
            "load_in_4bit": true,
            "load_in_8bit": false,
            "quant_method": "BITS_AND_BYTES",
            "_load_in_4bit": true,
            "_load_in_8bit": false,
            "llm_int8_threshold": 6,
            "bnb_4bit_quant_type": "nf4",
            "llm_int8_skip_modules": null,
            "bnb_4bit_compute_dtype": "float16",
            "bnb_4bit_quant_storage": "uint8",
            "llm_int8_has_fp16_weight": false,
            "bnb_4bit_use_double_quant": true,
            "llm_int8_enable_fp32_cpu_offload": false
        }
    },
    "skip_memory_metrics": {
        "value": true
    },
    "tie_encoder_decoder": {
        "value": false
    },
    "tie_word_embeddings": {
        "value": true
    },
    "auto_find_batch_size": {
        "value": false
    },
    "completion_only_loss": {
        "value": null
    },
    "dataloader_drop_last": {
        "value": false
    },
    "model/num_parameters": {
        "value": 1738007552
    },
    "no_repeat_ngram_size": {
        "value": 0
    },
    "num_return_sequences": {
        "value": 1
    },
    "optim_target_modules": {
        "value": null
    },
    "output_hidden_states": {
        "value": false
    },
    "overwrite_output_dir": {
        "value": false
    },
    "prediction_loss_only": {
        "value": false
    },
    "push_to_hub_model_id": {
        "value": null
    },
    "task_specific_params": {
        "value": null
    },
    "transformers_version": {
        "value": "4.57.3"
    },
    "activation_offloading": {
        "value": false
    },
    "begin_suppress_tokens": {
        "value": null
    },
    "dataloader_pin_memory": {
        "value": true
    },
    "ddp_broadcast_buffers": {
        "value": null
    },
    "metric_for_best_model": {
        "value": "eval_loss"
    },
    "remove_invalid_values": {
        "value": false
    },
    "remove_unused_columns": {
        "value": true
    },
    "torch_compile_backend": {
        "value": null
    },
    "dataloader_num_workers": {
        "value": 0
    },
    "decoder_start_token_id": {
        "value": null
    },
    "eval_do_concat_batches": {
        "value": true
    },
    "eval_use_gather_object": {
        "value": false
    },
    "gradient_checkpointing": {
        "value": true
    },
    "half_precision_backend": {
        "value": "auto"
    },
    "label_smoothing_factor": {
        "value": 0
    },
    "load_best_model_at_end": {
        "value": true
    },
    "logging_nan_inf_filter": {
        "value": true
    },
    "resume_from_checkpoint": {
        "value": null
    },
    "chunk_size_feed_forward": {
        "value": 0
    },
    "eval_accumulation_steps": {
        "value": null
    },
    "max_position_embeddings": {
        "value": 40960
    },
    "per_gpu_eval_batch_size": {
        "value": null
    },
    "return_dict_in_generate": {
        "value": false
    },
    "torch_empty_cache_steps": {
        "value": null
    },
    "per_gpu_train_batch_size": {
        "value": null
    },
    "push_to_hub_organization": {
        "value": null
    },
    "include_tokens_per_second": {
        "value": false
    },
    "dataloader_prefetch_factor": {
        "value": null
    },
    "ddp_find_unused_parameters": {
        "value": true
    },
    "include_inputs_for_metrics": {
        "value": false
    },
    "per_device_eval_batch_size": {
        "value": 16
    },
    "use_legacy_prediction_loop": {
        "value": false
    },
    "cross_attention_hidden_size": {
        "value": null
    },
    "gradient_accumulation_steps": {
        "value": 2
    },
    "per_device_train_batch_size": {
        "value": 8
    },
    "encoder_no_repeat_ngram_size": {
        "value": 0
    },
    "average_tokens_across_devices": {
        "value": true
    },
    "dataloader_persistent_workers": {
        "value": false
    },
    "gradient_checkpointing_kwargs": {
        "value": null
    },
    "include_num_input_tokens_seen": {
        "value": "no"
    },
    "exponential_decay_length_penalty": {
        "value": null
    },
    "fsdp_transformer_layer_cls_to_wrap": {
        "value": null
    },
    "restore_callback_states_from_checkpoint": {
        "value": false
    }
}